{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "APPEND_JOB = False \n",
        "\"\"\"\n",
        "INPUT PARAMETERS\n",
        "\"\"\"\n",
        "#OmegaFold\n",
        "NAME = \"test\"\n",
        "SEQUENCE = \"\" #IMPORTANT: Only fasta files unlike AlphaFold\"\n",
        "#Advanced\n",
        "MODEL = 1 #Model 2 at the moment crashes due to lack of GPU memory\n",
        "\n",
        "\"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "ONE_JOB = not APPEND_JOB\n",
        "import os #WE USE ABSOLUTE PATHS\n",
        "#CUDA\n",
        "ENVIRONMENT = \"ProteinEnv\"\n",
        "#General\n",
        "MODELS_OUTPUT_FOLDER = \"scratch\" #Where to store output (subfolders will be created inside)\n",
        "INSTALLATION_FOLDER = \"data\"\n",
        "#GENERAL FOLDERS\n",
        "NOTEBOOKS_FOLDER = os.getcwd()\n",
        "PIPELINES_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"Pipelines\")\n",
        "PDBs_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"PDBs\")\n",
        "HELP_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"HelpScripts\")\n",
        "USER_NAME = os.path.basename(os.path.dirname(NOTEBOOKS_FOLDER))\n",
        "HOME_FOLDER = f\"/home/{USER_NAME}\"\n",
        "DATA_FOLDER = f\"/data/{USER_NAME}\"\n",
        "SCRATCH_FOLDER = f\"/scratch/{USER_NAME}\"\n",
        "#MODIFIABLE FOLDERS\n",
        "INSTALLATION_FOLDER = DATA_FOLDER\n",
        "MODELS_OUTPUT_FOLDER = os.path.join(SCRATCH_FOLDER,\"ProteinOutput\")\n",
        "if not os.path.exists(MODELS_OUTPUT_FOLDER):\n",
        "    os.mkdir(MODELS_OUTPUT_FOLDER)\n",
        "#MODELS\n",
        "OMEGA_FOLDER = os.path.join(INSTALLATION_FOLDER,\"OmegaFold\")\n",
        "OUT_FOLDER = os.path.join(MODELS_OUTPUT_FOLDER,\"OmegaFold\")\n",
        "if not os.path.exists(OUT_FOLDER):\n",
        "    os.mkdir(OUT_FOLDER)\n",
        "\n",
        "#This will be used throughout to generate file and directory names to avoid overriding old outputs\n",
        "def unique_name(directory,root,ext = \"\",fullpath=0,w=3):   \n",
        "    i = 1     \n",
        "    u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    while os.path.exists(os.path.join(directory,u_name+ext)):\n",
        "        i += 1\n",
        "        u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    if fullpath: return os.path.join(directory, u_name + ext)\n",
        "    return u_name + ext\n",
        "\n",
        "\"\"\"\n",
        "SET JOB NAME AND CREATE OUTPUT DIRECTORIES\n",
        "Data are stored in the \"of_output\" folder inside the data folder\n",
        "Also, a folder containg all the results is created inside that folder\n",
        "\"\"\"\n",
        "JOB = unique_name(OUT_FOLDER,NAME)\n",
        "JOB_FOLDER = os.path.join(OUT_FOLDER,JOB)\n",
        "os.mkdir(JOB_FOLDER)\n",
        "BASH_FOLDER = os.path.join(JOB_FOLDER,\"bash_files\")\n",
        "if not os.path.exists(BASH_FOLDER):\n",
        "    os.mkdir(BASH_FOLDER)\n",
        "#Output from console will also be redirected to log files\n",
        "of_log_file = os.path.join(JOB_FOLDER,\"of.log\")\n",
        "of_pse_log_file = os.path.join(JOB_FOLDER,\"of_pse.log\")\n",
        "\n",
        "\"\"\"OMEGAFOLD\"\"\"\n",
        "if SEQUENCE.endswith(\".fasta\"):\n",
        "    queries_fasta_file = os.path.join(os.getcwd(),SEQUENCE)\n",
        "else:\n",
        "    queries_fasta_file = os.path.join(JOB_FOLDER,\"of_queries.fasta\") #This will contain the queries\n",
        "    with open(queries_fasta_file,\"w\") as queries_fasta:\n",
        "        queries_fasta.write(f\">{NAME}\\n{SEQUENCE}\")\n",
        "\n",
        "of_options = \"\"\n",
        "of_options += f\"--model {MODEL}\"\n",
        "\"\"\" OPTIONS NOT IMPLEMENTED\n",
        "--num_cycle NUM_CYCLE\n",
        "--device DEVICE\n",
        "--subbatch_size {SUBBATCH_SIZE}\n",
        "--weights WEIGHTS\n",
        "--pseudo_msa_mask_rate PSEUDO_MSA_MASK_RATE\n",
        "--num_pseudo_msa NUM_PSEUDO_MSA\n",
        "--allow_tf32 ALLOW_TF32\"\"\"\n",
        "weights_pt = [\"\",\"release1.pt\",\"release2.pt\"][MODEL]\n",
        "weights_pt_file = os.path.join(OMEGA_FOLDER,weights_pt)\n",
        "of_options += f\" --weights_file {weights_pt_file}\"\n",
        "of_sh_file = unique_name(BASH_FOLDER,\"of\",\".sh\",1)\n",
        "of_cmd = f\"\"\"\n",
        "echo Initializing model...\n",
        "omegafold {queries_fasta_file} {JOB_FOLDER} {of_options}\n",
        "\"\"\"\n",
        "with open(of_sh_file,'w') as of_sh:\n",
        "    of_sh.write(of_cmd)\n",
        "os.chmod(of_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"PSE CREATION\"\"\"\n",
        "of_pse_py_file = os.path.join(HELP_FOLDER,\"make_pse_of.py\")\n",
        "of_pse_file = os.path.join(JOB_FOLDER,NAME+\".pse\")\n",
        "of_pse_cmd = f\"python {of_pse_py_file} {JOB_FOLDER} {of_pse_file}\"\n",
        "of_pse_sh_file = unique_name(BASH_FOLDER,\"pmpnn_of_rank\",\".sh\",1)\n",
        "with open(of_pse_sh_file,'w') as pse_sh:\n",
        "    pse_sh.write(of_pse_cmd)\n",
        "os.chmod(of_pse_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"COMBINE ALL IN A UNIQUE PIPELINE\"\"\"\n",
        "pipeline_sh_file = unique_name(BASH_FOLDER,\"pipeline\",\".sh\",1)\n",
        "pipeline_cmd = f\"\"\"\n",
        "echo Pipeline: {os.path.basename(pipeline_sh_file)}\n",
        "echo\n",
        "echo Name: {NAME}\n",
        "echo SEQUENCE: {SEQUENCE}\n",
        "\n",
        "source activate {ENVIRONMENT}\n",
        "echo\n",
        "echo OmegaFold\n",
        "{of_sh_file} | tee {of_log_file}\n",
        "echo\n",
        "echo PyMol\n",
        "{of_pse_sh_file} | tee {of_pse_log_file}\n",
        "echo \n",
        "echo Job done\n",
        "echo {JOB_FOLDER}\n",
        "\"\"\"\n",
        "with open(pipeline_sh_file,'w') as pipeline_sh:\n",
        "    pipeline_sh.write(pipeline_cmd)\n",
        "os.chmod(pipeline_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "batch_sh_file = os.path.join(PIPELINES_FOLDER,\"of_batch.sh\")\n",
        "if not ONE_JOB and os.path.exists(batch_sh_file):\n",
        "    with open(batch_sh_file,\"r\") as of_batch_sh:\n",
        "        previous_pipelines = of_batch_sh.readlines()\n",
        "    with open(batch_sh_file,\"w\") as of_batch_sh:\n",
        "        of_batch_sh.writelines(previous_pipelines)\n",
        "        of_batch_sh.write(\"\\n\")\n",
        "        of_batch_sh.write(pipeline_sh_file)  \n",
        "else:      \n",
        "    with open(batch_sh_file,\"w\") as of_batch_sh:\n",
        "        of_batch_sh.write(pipeline_sh_file)  \n",
        "os.chmod(batch_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "print(\"Run using next cell\")\n",
        "print(f\"Single job:\\n{pipeline_sh_file}\")\n",
        "print(f\"Batch:\\n{batch_sh_file}\")\n",
        "print(f\"\\nOutput of this pipeline will be in:\\n{JOB_FOLDER}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "/home/$USER/ProteinNotebooks/Pipelines/of_batch.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MAKE SLURM FILE\n",
        "\"\"\"\n",
        "PACKAGE_MANAGER = \"mamba\"\n",
        "GPU = \"gpu\" #options: \"gpu\" (first available), \"t4\", \"v100\", \"v100-32g\", \"a100\"\n",
        "\n",
        "slurm_file = unique_name(PIPELINES_FOLDER,\"of_slurm\",\".sh\",1)\n",
        "with open(batch_sh_file,\"r\") as of_batch_sh:\n",
        "    all_pipelines = of_batch_sh.readlines()\n",
        "with open(slurm_file,\"w\") as slurm_bash:\n",
        "    slurm_bash.write(f\"module load {PACKAGE_MANAGER}\\n\")\n",
        "    slurm_bash.write(f\"module load {GPU}\\n\")\n",
        "    slurm_bash.writelines(all_pipelines)\n",
        "os.chmod(slurm_file, 0o755)\n",
        "\n",
        "print(f\"\"\"\n",
        "ScienceApps > Jobs > JobComposer > New Job > From Default Template    \n",
        "Edit Job name from Job Options.\n",
        "Replace job.sh (Open in Editor) with the following (adapt required time hh:mm:ss) then Save:\n",
        "      \n",
        "#!/usr/bin/bash\n",
        "#SBATCH --gpus=1\n",
        "#SBATCH --mem=7800\n",
        "#SBATCH --time=23:59:00\n",
        "#SBATCH --output=job.out      \n",
        "{slurm_file}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Conventions for names\n",
        "Paths to files end with _type_file\n",
        "Paths to folders end with _FOLDER\n",
        "Opened files .type end with _type\n",
        "Content of .sh end with _cmd\n",
        "Content of .py end with _script\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Cleanup instructions\n",
        "Delete data/bash_files\n",
        "Delete outputs folder: contains log files\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQXlWEjIOsf"
      },
      "source": [
        "**Instructions**\n",
        "---\n",
        "---\n",
        "\n",
        "Use `contigs` to define continious chains. Use a `:` to define multiple contigs and a `/` to define mutliple segments within a contig.\n",
        "For example:\n",
        "\n",
        "**unconditional**\n",
        "- `contigs='100'` - diffuse **monomer** of length 100\n",
        "- `contigs='50:100'` - diffuse **hetero-oligomer** of lengths 50 and 100\n",
        "- `contigs='50'` `symmetry='cyclic'` `order=2` - make two copies of the defined contig(s) and add a symmetry constraint, for **homo-oligomeric** diffusion.\n",
        "\n",
        "**binder design**\n",
        "- `contigs='A:50'` `pdb='4N5T'` - diffuse a **binder** of length 50 to chain A of defined PDB.\n",
        "- `contigs='E6-155:70-100'` `pdb='5KQV'` `hotspot='E64,E88,E96'` - diffuse a **binder** of length 70 to 100 (sampled randomly) to chain E and defined hotspot(s).\n",
        "\n",
        "**motif scaffolding**\n",
        " - `contigs='40/A163-181/40'` `pdb='5TPN'`\n",
        " - `contigs='A3-30/36/A33-68'` `pdb='6MRR'` - diffuse a loop of length 36 between two segments of defined PDB ranges.\n",
        "\n",
        "**partial diffusion**\n",
        "- `contigs=''` `pdb='6MRR'` - noise all coordinates\n",
        "- `contigs='A1-10'` `pdb='6MRR'` - keep first 10 positions fixed, noise the rest\n",
        "- `contigs='A'` `pdb='1SSC'` - fix chain A, noise the rest\n",
        "\n",
        "*hints and tips*\n",
        "- `pdb=''` leave blank to get an upload prompt\n",
        "- `contigs='50-100'` use dash to specify a range of lengths to sample from"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
