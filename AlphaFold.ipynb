{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "APPEND_JOB = False \n",
        "\"\"\"\n",
        "INPUT PARAMETERS\n",
        "\"\"\"\n",
        "#AlphaFold\n",
        "NAME = \"test\"\n",
        "SEQUENCE = \"\" #Instead of providing the sequence, you can provide the relative path ot a csv file. Important: it must contain two columns named \"id\" and \"sequence\"\n",
        "#Advanced\n",
        "NUM_RELAX = 0 #How many of the best-ranked models do you want to relax with amber?\n",
        "NUM_RECYCLE = 3 #Default (and recommended) is 3\n",
        "RAND_SEED = 0\n",
        "#Pymol\n",
        "ONLY_FIRST = True #Only compare the best folding of each sequence generated\n",
        "\n",
        "\"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "ONE_JOB = not APPEND_JOB\n",
        "import os #WE USE ABSOLUTE PATHS\n",
        "#CUDA\n",
        "ENVIRONMENT = \"ProteinEnv\"\n",
        "#General\n",
        "MODELS_OUTPUT_FOLDER = \"scratch\" #Where to store output (subfolders will be created inside)\n",
        "INSTALLATION_FOLDER = \"data\"\n",
        "#GENERAL FOLDERS\n",
        "NOTEBOOKS_FOLDER = os.getcwd()\n",
        "PIPELINES_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"Pipelines\")\n",
        "PDBs_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"PDBs\")\n",
        "HELP_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"HelpScripts\")\n",
        "USER_NAME = os.path.basename(os.path.dirname(NOTEBOOKS_FOLDER))\n",
        "HOME_FOLDER = f\"/home/{USER_NAME}\"\n",
        "DATA_FOLDER = f\"/data/{USER_NAME}\"\n",
        "SCRATCH_FOLDER = f\"/scratch/{USER_NAME}\"\n",
        "#MODIFIABLE FOLDERS\n",
        "INSTALLATION_FOLDER = DATA_FOLDER\n",
        "MODELS_OUTPUT_FOLDER = os.path.join(SCRATCH_FOLDER,\"ProteinOutput\")\n",
        "if not os.path.exists(MODELS_OUTPUT_FOLDER):\n",
        "    os.mkdir(MODELS_OUTPUT_FOLDER)\n",
        "#MODELS\n",
        "COLAB_FOLD_FOLDER = os.path.join(INSTALLATION_FOLDER,\"localcolabfold\")\n",
        "PROTEIN_OUTPUT_FOLDER = os.path.join(MODELS_OUTPUT_FOLDER,\"ProteinOutput\")\n",
        "OUT_FOLDER = os.path.join(MODELS_OUTPUT_FOLDER,\"AlphaFold\")\n",
        "if not os.path.exists(OUT_FOLDER):\n",
        "    os.mkdir(OUT_FOLDER)\n",
        "\n",
        "#This will be used throughout to generate file and directory names to avoid overriding old outputs\n",
        "def unique_name(directory,root,ext = \"\",fullpath=0,w=3):   \n",
        "    i = 1     \n",
        "    u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    while os.path.exists(os.path.join(directory,u_name+ext)):\n",
        "        i += 1\n",
        "        u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    if fullpath: return os.path.join(directory, u_name + ext)\n",
        "    return u_name + ext\n",
        "\n",
        "\"\"\"\n",
        "SET JOB NAME AND CREATE OUTPUT DIRECTORIES\n",
        "Data are stored in the \"AF2_output\" folder inside the data folder\n",
        "Also, a folder containg all the results is created inside that folder\n",
        "\"\"\"\n",
        "JOB = unique_name(OUT_FOLDER,NAME)\n",
        "JOB_FOLDER = os.path.join(OUT_FOLDER,JOB)\n",
        "os.mkdir(JOB_FOLDER)\n",
        "BASH_FOLDER = os.path.join(JOB_FOLDER,\"bash_files\")\n",
        "if not os.path.exists(BASH_FOLDER):\n",
        "    os.mkdir(BASH_FOLDER)\n",
        "#Output from console will also be redirected to log files\n",
        "af2_log_file = os.path.join(JOB_FOLDER,\"af2.log\")\n",
        "af2_pse_log_file = os.path.join(JOB_FOLDER,\"af2_pse.log\")\n",
        "\n",
        "\"\"\"ALPHAFOLD\"\"\"\n",
        "if SEQUENCE.endswith(\".csv\"):\n",
        "    queries_csv_file = os.path.join(os.getcwd(),SEQUENCE)\n",
        "else:\n",
        "    queries_csv_file = os.path.join(JOB_FOLDER,\"af2_queries.csv\") #This will contain the queries\n",
        "    with open(queries_csv_file,\"w\") as queries_csv:\n",
        "        queries_csv.write(f\"id,sequence\\n{NAME},{SEQUENCE}\")\n",
        "\n",
        "af2_options = \"\"\n",
        "if NUM_RELAX > 0: af2_options += f\" --amber --use-gpu-relax --num-relax {NUM_RELAX}\" #assumed to run on GPU\n",
        "if NUM_RECYCLE != 3: af2_options += f\" --num-recycle {NUM_RECYCLE}\"\n",
        "if RAND_SEED != 0: af2_options += f\" --random-seed {RAND_SEED}\"\n",
        "\n",
        "colabfold_batch_file = os.path.join(COLAB_FOLD_FOLDER,\"colabfold-conda/bin/colabfold_batch\")\n",
        "af2_sh_file = unique_name(BASH_FOLDER,\"af2\",\".sh\",1)\n",
        "af2_cmd = f\"\"\"\n",
        "echo Initializing model...\n",
        "{colabfold_batch_file} {queries_csv_file} {JOB_FOLDER} {af2_options}\n",
        "\"\"\"\n",
        "with open(af2_sh_file,'w') as af2_sh:\n",
        "    af2_sh.write(af2_cmd)\n",
        "os.chmod(af2_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"PSE CREATION\"\"\"\n",
        "af2_pse_py_file = os.path.join(HELP_FOLDER,\"make_pse_af2.py\")\n",
        "af2_pse_file = os.path.join(JOB_FOLDER,NAME+\".pse\")\n",
        "af2_pse_cmd = f\"python {af2_pse_py_file} {JOB_FOLDER} {af2_pse_file} {ONLY_FIRST}\"\n",
        "af2_pse_sh_file = unique_name(BASH_FOLDER,\"pmpnn_af2_rank\",\".sh\",1)\n",
        "with open(af2_pse_sh_file,'w') as pse_sh:\n",
        "    pse_sh.write(af2_pse_cmd)\n",
        "os.chmod(af2_pse_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"COMBINE ALL IN A UNIQUE PIPELINE\"\"\"\n",
        "pipeline_sh_file = unique_name(BASH_FOLDER,\"pipeline\",\".sh\",1)\n",
        "print_options_cmd = f\"\"\"\n",
        "echo Pipeline: {os.path.basename(pipeline_sh_file)}\n",
        "echo\n",
        "echo Name: {NAME}\n",
        "echo SEQUENCE: {SEQUENCE}\n",
        "\"\"\"\n",
        "pipeline_cmd = print_options_cmd + f\"\"\"\n",
        "source activate {ENVIRONMENT}\n",
        "echo\n",
        "echo AlphaFold\n",
        "{af2_sh_file} | tee {af2_log_file}\n",
        "echo\n",
        "echo PyMol\n",
        "{af2_pse_sh_file} | tee {af2_pse_log_file}\n",
        "echo \n",
        "echo Job done\n",
        "echo {JOB_FOLDER}\n",
        "\"\"\"\n",
        "with open(pipeline_sh_file,'w') as pipeline_sh:\n",
        "    pipeline_sh.write(pipeline_cmd)\n",
        "os.chmod(pipeline_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "#write configuration file\n",
        "config_txt_file = os.path.join(JOB_FOLDER,NAME+\"_config.txt\")\n",
        "with open(config_txt_file,'w') as config_txt:\n",
        "    config_txt.write(print_options_cmd)\n",
        "\n",
        "batch_sh_file = os.path.join(PIPELINES_FOLDER,\"af2_batch.sh\")\n",
        "if not ONE_JOB and os.path.exists(batch_sh_file):\n",
        "    with open(batch_sh_file,\"r\") as af2_batch_sh:\n",
        "        previous_pipelines = af2_batch_sh.readlines()\n",
        "    with open(batch_sh_file,\"w\") as af2_batch_sh:\n",
        "        af2_batch_sh.writelines(previous_pipelines)\n",
        "        af2_batch_sh.write(\"\\n\")\n",
        "        af2_batch_sh.write(pipeline_sh_file)  \n",
        "else:      \n",
        "    with open(batch_sh_file,\"w\") as af2_batch_sh:\n",
        "        af2_batch_sh.write(pipeline_sh_file)  \n",
        "os.chmod(batch_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "print(\"Run using next cell\")\n",
        "print(f\"Single job:\\n{pipeline_sh_file}\")\n",
        "print(f\"Batch:\\n{batch_sh_file}\")\n",
        "print(f\"\\nOutput of this pipeline will be in:\\n{JOB_FOLDER}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "/home/$USER/ProteinNotebooks/Pipelines/af2_batch.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MAKE SLURM FILE\n",
        "\"\"\"\n",
        "PACKAGE_MANAGER = \"mamba\"\n",
        "GPU = \"gpu\" \n",
        "\"\"\"\n",
        "GPUs available are:\n",
        "T4      0.022 CHF/h\n",
        "V100    0.057 CHF/h\n",
        "A100    0.081 CHF/h\n",
        "These can be allocated by setting GPU = \"T4\", \"V100\", or \"A100\"\n",
        "By setting GPU=\"gpu\", the first available will be used\n",
        "By setting GPU=\"high-memory\", either v100-32gb or a100 are selected. \n",
        "Important: OmegaFold model 2 only works with high-memory GPUs. Sometimes it fails with 32G as well, so it is safer to use A100\n",
        "\"\"\"\n",
        "\n",
        "slurm_file = unique_name(PIPELINES_FOLDER,\"af2_slurm\",\".sh\",1)\n",
        "with open(batch_sh_file,\"r\") as rfd_batch_sh:\n",
        "    all_pipelines = rfd_batch_sh.readlines()\n",
        "with open(slurm_file,\"w\") as slurm_bash:\n",
        "    slurm_bash.write(\"\"\"# Check if nvidia-smi is available\n",
        "if ! command -v nvidia-smi &> /dev/null\n",
        "then\n",
        "    echo \"Could not load GPU correctly: nvidia-smi could not be found\"\n",
        "    exit\n",
        "fi\n",
        "gpu_type=$(nvidia-smi --query-gpu=gpu_name --format=csv,noheader)\n",
        "echo \"GPU Type: $gpu_type\"\\n\n",
        "\"\"\")\n",
        "    slurm_bash.write(f\"module load {PACKAGE_MANAGER}\\n\")\n",
        "    slurm_bash.writelines(all_pipelines)\n",
        "os.chmod(slurm_file, 0o755)\n",
        "\n",
        "if GPU == \"high-memory\":\n",
        "    gpu_line = \"#SBATCH --gpus=1\\n#SBATCH --constraint=\\\"GPUMEM32GB|GPUMEM80GB\\\"\"\n",
        "elif GPU == \"gpu\":\n",
        "    gpu_line = \"#SBATCH --gpus=1\"\n",
        "else:\n",
        "    gpu_line = f\"#SBATCH --gpus={GPU}:1\"\n",
        "\n",
        "print(f\"\"\"\n",
        "ScienceApps > Jobs > JobComposer > New Job > From Default Template    \n",
        "Edit Job name from Job Options.\n",
        "Replace job.sh (Open in Editor) with the following (adapt required time hh:mm:ss) then Save:\n",
        "      \n",
        "#!/usr/bin/bash\n",
        "{gpu_line}\n",
        "#SBATCH --mem=7800\n",
        "#SBATCH --time=23:59:00\n",
        "#SBATCH --output=job.out      \n",
        "{slurm_file}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Conventions for names\n",
        "Paths to files end with _type_file\n",
        "Paths to folders end with _FOLDER\n",
        "Opened files .type end with _type\n",
        "Content of .sh end with _cmd\n",
        "Content of .py end with _script\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Cleanup instructions\n",
        "Delete data/bash_files\n",
        "Delete outputs folder: contains log files\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQXlWEjIOsf"
      },
      "source": [
        "**Instructions**\n",
        "---\n",
        "---\n",
        "\n",
        "Use `contigs` to define continious chains. Use a `:` to define multiple contigs and a `/` to define mutliple segments within a contig.\n",
        "For example:\n",
        "\n",
        "**unconditional**\n",
        "- `contigs='100'` - diffuse **monomer** of length 100\n",
        "- `contigs='50:100'` - diffuse **hetero-oligomer** of lengths 50 and 100\n",
        "- `contigs='50'` `symmetry='cyclic'` `order=2` - make two copies of the defined contig(s) and add a symmetry constraint, for **homo-oligomeric** diffusion.\n",
        "\n",
        "**binder design**\n",
        "- `contigs='A:50'` `pdb='4N5T'` - diffuse a **binder** of length 50 to chain A of defined PDB.\n",
        "- `contigs='E6-155:70-100'` `pdb='5KQV'` `hotspot='E64,E88,E96'` - diffuse a **binder** of length 70 to 100 (sampled randomly) to chain E and defined hotspot(s).\n",
        "\n",
        "**motif scaffolding**\n",
        " - `contigs='40/A163-181/40'` `pdb='5TPN'`\n",
        " - `contigs='A3-30/36/A33-68'` `pdb='6MRR'` - diffuse a loop of length 36 between two segments of defined PDB ranges.\n",
        "\n",
        "**partial diffusion**\n",
        "- `contigs=''` `pdb='6MRR'` - noise all coordinates\n",
        "- `contigs='A1-10'` `pdb='6MRR'` - keep first 10 positions fixed, noise the rest\n",
        "- `contigs='A'` `pdb='1SSC'` - fix chain A, noise the rest\n",
        "\n",
        "*hints and tips*\n",
        "- `pdb=''` leave blank to get an upload prompt\n",
        "- `contigs='50-100'` use dash to specify a range of lengths to sample from"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
