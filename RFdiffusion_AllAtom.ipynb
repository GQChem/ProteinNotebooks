{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "APPEND_JOB = False \n",
        "\"\"\"\n",
        "INPUT PARAMETERS\n",
        "\"\"\"\n",
        "#Do not use the words \"design\", \"rank\" in the names or pdb files as these ar keywords for functionality of the code\n",
        "\n",
        "\"\"\"RFdiffusion-All-Atom\"\"\"\n",
        "NAME = \"\" #if empty, the name will be the PDB\n",
        "PDB = \"\" #pdb (upload not implemented)\n",
        "LIGAND = \"\" #Name of the ligand in the PDB file\n",
        "CONTIGS = \"\" #[] will be added automatically\n",
        "NUM_DESIGNS = 1\n",
        "#Advanced\n",
        "STEPS = 100 \n",
        "PARTIAL_STEPS = 0 #Steps of partial diffusion. Contig string must be exactly the same length as the input protein (see official documentation)\n",
        "REPRODUCIBLE = False\n",
        "REPRODUCIBILITY_NUMBER = 0\n",
        "\"\"\"ProteinMPNN\"\"\"\n",
        "NUM_SEQ_PER_TARGET = 1\n",
        "FIXED = \"rfd\" #Can be either \"\" (none) or \"rfd\" (scaffold is fixed) or a pymol-formatted selection e.g. \"10-15+17+20-54\" \n",
        "FIXED_CHAIN = \"A\" #To be implemented: possibility to fix more than one chain\n",
        "#Advanced\n",
        "SAMPLING_T = \"0.1\"\n",
        "\"\"\"FOLD\"\"\"\n",
        "FOLD = \"OF\" #Choices are AF for AlphaFold and OF for OmegaFold\n",
        "#AlphaFold\n",
        "ONLY_FIRST = True #Only compare the best folding of each sequence generated \n",
        "#Advanced\n",
        "NUM_RELAX = 0 #How many of the best-ranked models do you want to relax with amber?\n",
        "NUM_RECYCLE = 3 #Default (and recommended) is 3\n",
        "RAND_SEED = 0\n",
        "#OmegaFold\n",
        "MODEL = 1 #Model 2 at the moment crashes due to lack of GPU memorywell\n",
        "#Ranking\n",
        "METRIC = \"pLDDT\" #\"pLDDT\" or \"pTM\" or \"RMSD\". pTM not available in omegafold\n",
        "PYMOL_BEST = 10 #Create a pymol session contaning the N best models aligned with the \n",
        "#Refolding and reranking for models other than alphafold\n",
        "FOLD_BEST_WITH_ALPHAFOLD = 0 \n",
        "\n",
        "\"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "#Quick refinement of input\n",
        "ONE_JOB = not APPEND_JOB\n",
        "if FOLD == \"AF\": FOLD = \"AlphaFold\"\n",
        "elif FOLD == \"OF\": FOLD = \"OmegaFold\"\n",
        "\n",
        "import os,shutil #WE USE ABSOLUTE PATHS\n",
        "#CUDA\n",
        "ENVIRONMENT = \"ProteinEnv\"\n",
        "#General\n",
        "MODELS_OUTPUT_FOLDER = \"scratch\" #Where to store output (subfolders will be created inside)\n",
        "INSTALLATION_FOLDER = \"data\"\n",
        "#GENERAL FOLDERS\n",
        "NOTEBOOKS_FOLDER = os.getcwd()\n",
        "PIPELINES_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"Pipelines\")\n",
        "PDBs_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"PDBs\")\n",
        "HELP_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"HelpScripts\")\n",
        "USER_NAME = os.path.basename(os.path.dirname(NOTEBOOKS_FOLDER))\n",
        "HOME_FOLDER = f\"/home/{USER_NAME}\"\n",
        "DATA_FOLDER = f\"/data/{USER_NAME}\"\n",
        "SCRATCH_FOLDER = f\"/scratch/{USER_NAME}\"\n",
        "#MODIFIABLE FOLDERS\n",
        "INSTALLATION_FOLDER = DATA_FOLDER\n",
        "MODELS_OUTPUT_FOLDER = os.path.join(SCRATCH_FOLDER,\"ProteinOutput\")\n",
        "if not os.path.exists(MODELS_OUTPUT_FOLDER):\n",
        "    os.mkdir(MODELS_OUTPUT_FOLDER)\n",
        "#MODELS\n",
        "RFD_AA_FOLDER = os.path.join(INSTALLATION_FOLDER,\"rf_diffusion_all_atom\")\n",
        "PMPNN_FOLDER = os.path.join(INSTALLATION_FOLDER,\"ProteinMPNN\")\n",
        "LMPNN_FOLDER = os.path.join(INSTALLATION_FOLDER,\"LigandMPNN\")\n",
        "OMEGA_FOLDER = os.path.join(INSTALLATION_FOLDER,\"OmegaFold\")\n",
        "COLAB_FOLD_FOLDER = os.path.join(INSTALLATION_FOLDER,\"localcolabfold\")\n",
        "OUT_FOLDER = os.path.join(MODELS_OUTPUT_FOLDER,\"RFdiffusion_AllAtom\")\n",
        "if not os.path.exists(OUT_FOLDER):\n",
        "    os.mkdir(OUT_FOLDER)\n",
        "\n",
        "#This will be used throughout to generate file and directory names to avoid overriding old outputs\n",
        "def unique_name(directory,root,ext = \"\",fullpath=0,w=3):   \n",
        "    i = 1     \n",
        "    u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    while os.path.exists(os.path.join(directory,u_name+ext)):\n",
        "        i += 1\n",
        "        u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    if fullpath: return os.path.join(directory, u_name + ext)\n",
        "    return u_name + ext\n",
        "\n",
        "\"\"\"\n",
        "SET JOB NAME AND CREATE OUTPUT DIRECTORIES\n",
        "Data are stored in the \"RFD_output\" folder inside the data folder\n",
        "Also, a folder containg all the results is created inside that folder\n",
        "\"\"\"\n",
        "JOB_BASE = NAME if NAME != \"\" else os.path.splitext(os.path.basename(PDB))[0]\n",
        "JOB = unique_name(OUT_FOLDER,JOB_BASE)\n",
        "JOB_FOLDER = os.path.join(OUT_FOLDER,JOB)\n",
        "os.mkdir(JOB_FOLDER)\n",
        "BASH_FOLDER = os.path.join(JOB_FOLDER,\"bash_files\")\n",
        "if not os.path.exists(BASH_FOLDER):\n",
        "    os.mkdir(BASH_FOLDER)\n",
        "#Output from consol will also be redirected to log files\n",
        "rfd_log_file = os.path.join(JOB_FOLDER,\"rfd.log\")\n",
        "pmpnn_log_file = os.path.join(JOB_FOLDER,\"pmpnn.log\")\n",
        "fold_log_file = os.path.join(JOB_FOLDER,\"fold.log\")   #####changed af2 to fold\n",
        "ranking_log_file = os.path.join(JOB_FOLDER,\"ranking.log\")\n",
        "\n",
        "\"\"\"\n",
        "SET ARGUMENTS\n",
        "\"\"\"\n",
        "pdb_file = PDB\n",
        "pdb_temp = PDB if PDB.endswith(\".pdb\") else PDB + \".pdb\"\n",
        "pdb_temp_file = os.path.join(PDBs_FOLDER,pdb_temp)\n",
        "pdb_file = os.path.join(BASH_FOLDER,pdb_temp)\n",
        "shutil.copy(pdb_temp_file,pdb_file) #copy original input file into destination foler\n",
        "\n",
        "rfd_aa_weights_pt_file = os.path.join(RFD_AA_FOLDER,\"RFDiffusionAA_paper_weights.pt\")\n",
        "rfd_options = f\"contigmap.contigs=['{CONTIGS}']\"\n",
        "rfd_options += f\" inference.ckpt_override_path={rfd_aa_weights_pt_file}\"\n",
        "rfd_options += f\" inference.input_pdb={pdb_file}\"\n",
        "rfd_options += f\" inference.ligand={LIGAND}\"\n",
        "prefix = os.path.join(JOB_FOLDER,f\"{JOB}_design\") #polyG Designs will be .._design_0.pdb, .._design_1.pdb, ...\n",
        "rfd_options += f\" inference.output_prefix={prefix}\"\n",
        "rfd_options += f\" inference.num_designs={NUM_DESIGNS}\"\n",
        "rfd_options += f\" inference.deterministic={REPRODUCIBLE}\"\n",
        "rfd_options += f\" inference.design_startnum={REPRODUCIBILITY_NUMBER}\"\n",
        "if STEPS != 50: rfd_options += f\"diffuser.T = {STEPS}\"\n",
        "if PARTIAL_STEPS > 0: rfd_options += f\"diffuser.partial_T = {PARTIAL_STEPS}\"\n",
        "\n",
        "rfd_aa_sif_file = os.path.join(RFD_AA_FOLDER,\"rf_se3_diffusion.sif\")\n",
        "inference_py_file = os.path.join(RFD_AA_FOLDER,\"run_inference.py\")\n",
        "rfd_cmd = f\"\"\"\n",
        "singularity run --nv {rfd_aa_sif_file} -u {inference_py_file} {rfd_options}\n",
        "\"\"\"\n",
        "rfd_sh_file = unique_name(BASH_FOLDER,\"rfd\",\".sh\",1)\n",
        "with open(rfd_sh_file ,\"w\") as rfd_sh:\n",
        "    rfd_sh.write(rfd_cmd)\n",
        "os.chmod(rfd_sh_file, 0o755) #By default, the bash is created without execution rights, we add them here\n",
        "\n",
        "\"\"\"ProteinMPNN\"\"\"\n",
        "#Parse folder for multiple pdb input\n",
        "parsed_pdbs_jsonl_file = os.path.join(JOB_FOLDER,f\"{JOB}_parsed_pdbs.jsonl\")\n",
        "parse_py_file = os.path.join(PMPNN_FOLDER,\"helper_scripts/parse_multiple_chains.py\")\n",
        "fixed_jsonl_file = os.path.join(JOB_FOLDER,f\"{JOB}_fixed_pos.jsonl\")\n",
        "sele_csv_file = os.path.join(JOB_FOLDER,\"pmpnn_sele.csv\")\n",
        "\n",
        "#IMPLEMENTATION OF FIXED POSITIONS\n",
        "fixed_py_file = os.path.join(HELP_FOLDER,\"make_fixed_dict.py\")\n",
        "\n",
        "#Set options\n",
        "pmpnn_options = f\"--num_seq_per_target {NUM_SEQ_PER_TARGET}\"\n",
        "pmpnn_options += f\" --sampling_temp {SAMPLING_T}\"\n",
        "pmpnn_py_file = os.path.join(PMPNN_FOLDER,\"protein_mpnn_run.py\")\n",
        "\n",
        "pmpnn_sh_file = unique_name(BASH_FOLDER,\"rfd_pmpnn\",\".sh\",1)\n",
        "pmpnn_cmd = f\"\"\"\n",
        "echo Determining fixed positions\n",
        "python {fixed_py_file} {JOB_FOLDER} {rfd_log_file} 100 {FIXED} {FIXED_CHAIN} {fixed_jsonl_file} {sele_csv_file}\n",
        "echo Parsing multiple pbds \n",
        "python {parse_py_file} --input_path {JOB_FOLDER} --output_path {parsed_pdbs_jsonl_file}\n",
        "echo Running model\n",
        "python {pmpnn_py_file} --jsonl_path {parsed_pdbs_jsonl_file} --fixed_positions_jsonl {fixed_jsonl_file} --out_folder {JOB_FOLDER} {pmpnn_options}\n",
        "\"\"\"\n",
        "with open(pmpnn_sh_file,'w') as pmpnn_sh:\n",
        "    pmpnn_sh.write(pmpnn_cmd)\n",
        "os.chmod(pmpnn_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"FOLD\"\"\"\n",
        "FOLD_OUT_FOLDER = os.path.join(JOB_FOLDER,FOLD)\n",
        "if not os.path.exists(FOLD_OUT_FOLDER):\n",
        "    os.mkdir(FOLD_OUT_FOLDER)\n",
        "PMPNN_FA_FOLDER = os.path.join(JOB_FOLDER,\"seqs\") #This is the folder where pmpnn outputs fasta files\n",
        "queries_csv_file = os.path.join(JOB_FOLDER,\"queries.csv\") #These will contain the queries\n",
        "queries_fasta_file = os.path.join(JOB_FOLDER,\"queries.fasta\")\n",
        "fa_to_csv_fasta_py_file = os.path.join(HELP_FOLDER,\"fa_to_csv_fasta.py\")\n",
        "\n",
        "fold_sh_file = \"\"\n",
        "if FOLD == \"AlphaFold\":\n",
        "    af2_options = \"\"\n",
        "    if NUM_RELAX > 0: af2_options += f\" --amber --use-gpu-relax --num-relax {NUM_RELAX}\" #assumed to run on GPU\n",
        "    if NUM_RECYCLE != 3: af2_options += f\" --num-recycle {NUM_RECYCLE}\"\n",
        "    if RAND_SEED != 0: af2_options += f\" --random-seed {RAND_SEED}\"\n",
        "\n",
        "    colabfold_batch_file = os.path.join(COLAB_FOLD_FOLDER,\"colabfold-conda/bin/colabfold_batch\")\n",
        "    fold_sh_file = unique_name(BASH_FOLDER,\"rfd_pmpnn_af2\",\".sh\",1)\n",
        "    af2_cmd = f\"\"\"\n",
        "    echo Generating queries.csv file from .fa output\n",
        "    python {fa_to_csv_fasta_py_file} {PMPNN_FA_FOLDER} {queries_csv_file} {queries_fasta_file}\n",
        "    echo Initializing model...\n",
        "    {colabfold_batch_file} {queries_csv_file} {FOLD_OUT_FOLDER} {af2_options}\n",
        "    \"\"\"\n",
        "    with open(fold_sh_file,'w') as af2_sh:\n",
        "        af2_sh.write(af2_cmd)\n",
        "elif FOLD == \"OmegaFold\":\n",
        "    of_options = \"\"\n",
        "    of_options += f\" --model {MODEL}\"\n",
        "    weights_pt = [\"\",\"release1.pt\",\"release2.pt\"][MODEL]\n",
        "    weights_pt_file = os.path.join(OMEGA_FOLDER,weights_pt)\n",
        "    of_options += f\" --weights_file {weights_pt_file}\"\n",
        "    fold_sh_file = unique_name(BASH_FOLDER,\"rfd_pmpnn_of\",\".sh\",1)\n",
        "    of_cmd = f\"\"\"\n",
        "    echo Generating queries.csv file from .fa output\n",
        "    python {fa_to_csv_fasta_py_file} {PMPNN_FA_FOLDER} {queries_csv_file} {queries_fasta_file}\n",
        "    echo Initializing model...\n",
        "    omegafold {queries_fasta_file} {FOLD_OUT_FOLDER} {of_options}\n",
        "    \"\"\"\n",
        "    with open(fold_sh_file,'w') as of_sh:\n",
        "        of_sh.write(of_cmd)\n",
        "os.chmod(fold_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"RANK EVERYTHING\"\"\"\n",
        "rank_pdb = pdb_file if pdb_file != \"\" else \"-\"\n",
        "rank_output_csv_file = os.path.join(JOB_FOLDER,JOB_BASE+\".csv\")\n",
        "rank_pse_file = os.path.join(JOB_FOLDER,JOB_BASE+f\"_{FOLD}.pse\")\n",
        "rank_py_file = os.path.join(HELP_FOLDER,f\"rank_{FOLD}.py\")\n",
        "rank_cmd = f\"python {rank_py_file} {fold_log_file} {queries_csv_file} {NUM_SEQ_PER_TARGET} {sele_csv_file} {FOLD_OUT_FOLDER} {rank_pdb} {rank_output_csv_file} {METRIC} {rank_pse_file} {PYMOL_BEST} {ONLY_FIRST}\"\n",
        "rank_sh_file = unique_name(BASH_FOLDER,f\"rank_{FOLD}\",\".sh\",1)\n",
        "with open(rank_sh_file,'w') as rank_sh:\n",
        "    rank_sh.write(rank_cmd)\n",
        "os.chmod(rank_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"Additional step: fold best ones with AlphaFold\"\"\"\n",
        "if FOLD_BEST_WITH_ALPHAFOLD > 0 and not FOLD==\"AlphaFold\":\n",
        "    refold_log_file = os.path.join(JOB_FOLDER,\"af2_best_fold.log\")\n",
        "    reranking_log_file = os.path.join(JOB_FOLDER,\"reranking.log\")\n",
        "\n",
        "    ALPHAFOLD_OUT_FOLDER = os.path.join(JOB_FOLDER,\"AlphaFold\")\n",
        "    if not os.path.exists(ALPHAFOLD_OUT_FOLDER):\n",
        "        os.mkdir(ALPHAFOLD_OUT_FOLDER)\n",
        "\n",
        "    best_queries_py_file = os.path.join(HELP_FOLDER,\"best_queries.py\")\n",
        "    best_queries_csv_file = os.path.join(JOB_FOLDER,\"best_queries.csv\")\n",
        "\n",
        "    af2_options = \"\"\n",
        "    if NUM_RELAX > 0: af2_options += f\" --amber --use-gpu-relax --num-relax {NUM_RELAX}\" #assumed to run on GPU\n",
        "    if NUM_RECYCLE != 3: af2_options += f\" --num-recycle {NUM_RECYCLE}\"\n",
        "    if RAND_SEED != 0: af2_options += f\" --random-seed {RAND_SEED}\"\n",
        "\n",
        "    colabfold_batch_file = os.path.join(COLAB_FOLD_FOLDER,\"colabfold-conda/bin/colabfold_batch\")\n",
        "    af2_refolding_sh_file = unique_name(BASH_FOLDER,\"rfd_pmpnn_af2\",\".sh\",1)\n",
        "    af2_refolding_cmd = f\"\"\"\n",
        "    echo Selecting best queries {FOLD} output\n",
        "    python {best_queries_py_file} {queries_csv_file} {rank_output_csv_file} {FOLD_BEST_WITH_ALPHAFOLD} {best_queries_csv_file}\n",
        "    echo Initializing model...\n",
        "    {colabfold_batch_file} {best_queries_csv_file} {ALPHAFOLD_OUT_FOLDER} {af2_options}\n",
        "    \"\"\"\n",
        "    with open(af2_refolding_sh_file,'w') as af2_sh:\n",
        "        af2_sh.write(af2_refolding_cmd)\n",
        "    os.chmod(af2_refolding_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "    \"\"\"RERANK EVERYTHING\"\"\"\n",
        "    rerank_output_csv_file = os.path.join(JOB_FOLDER,JOB_BASE+\"_best_af2.csv\")\n",
        "    rerank_pse_file = os.path.join(JOB_FOLDER,JOB_BASE+f\"_AlphaFold.pse\")\n",
        "    rank_py_file = os.path.join(HELP_FOLDER,f\"RFdiffusion_rank_AlphaFold.py\")\n",
        "    rank_cmd = f\"python {rank_py_file} {refold_log_file} {best_queries_csv_file} {NUM_SEQ_PER_TARGET} {sele_csv_file} {ALPHAFOLD_OUT_FOLDER} {rank_pdb} {rerank_output_csv_file} {METRIC} {rerank_pse_file} {PYMOL_BEST} {ONLY_FIRST}\"\n",
        "    rerank_sh_file = unique_name(BASH_FOLDER,f\"RFdiffusion_Rank_AlphaFold\",\".sh\",1)\n",
        "    with open(rerank_sh_file,'w') as rank_sh:\n",
        "        rank_sh.write(rank_cmd)\n",
        "    os.chmod(rerank_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"COMBINE ALL IN A UNIQUE PIPELINE\"\"\"\n",
        "pipeline_sh_file = unique_name(PIPELINES_FOLDER,\"RFdiffusion_AllAtom_pipeline\",\".sh\",1)\n",
        "pipeline_cmd = f\"\"\"\n",
        "echo Pipeline: {os.path.basename(pipeline_sh_file)}\n",
        "echo\n",
        "echo Name: {NAME}\n",
        "echo PDB: {PDB}\n",
        "echo PDB PATH: {pdb_file}\n",
        "echo\n",
        "echo RFdiffusionAllAtom\n",
        "echo   CONTIGS: {CONTIGS}\n",
        "echo   NUM DESIGNS: {NUM_DESIGNS}\n",
        "echo   STEPS: {STEPS}\n",
        "echo   PARTIAL STEPS: {PARTIAL_STEPS}\n",
        "echo\n",
        "echo ProteinMPNN\n",
        "echo   NUM SEQUENCES PER TARGET: {NUM_SEQ_PER_TARGET}\n",
        "echo   FIXED: {FIXED}\n",
        "echo   FIXED CHAIN: {FIXED_CHAIN} \n",
        "echo   SAMPLING T: {SAMPLING_T}\n",
        "echo\n",
        "echo FOLD MODEL: {FOLD}\n",
        "echo   AlphaFold\n",
        "echo     NUM RELAX: {NUM_RELAX}\n",
        "echo     NUM RECYCLE: {NUM_RECYCLE}\n",
        "echo     RANDOM GENERATOR SEED: {RAND_SEED}\n",
        "echo   OmegaFold\n",
        "echo     MODEL: {MODEL}\n",
        "\n",
        "source activate {ENVIRONMENT}\n",
        "echo\n",
        "echo RFDiffusion\n",
        "{rfd_sh_file} | tee {rfd_log_file}\n",
        "echo\n",
        "echo ProteinMPNN\n",
        "{pmpnn_sh_file} | tee {pmpnn_log_file}\n",
        "echo\n",
        "echo {FOLD}\n",
        "{fold_sh_file} | tee {fold_log_file}\n",
        "echo \n",
        "echo Ranking...\n",
        "{rank_sh_file} | tee {ranking_log_file}\n",
        "\"\"\"\n",
        "if FOLD_BEST_WITH_ALPHAFOLD > 0 and not FOLD==\"AlphaFold\":\n",
        "    pipeline_cmd += f\"\"\"\n",
        "echo\n",
        "echo Refolding best {FOLD_BEST_WITH_ALPHAFOLD} proteins with AlphaFold\n",
        "echo\n",
        "echo AlphaFold\n",
        "{af2_refolding_sh_file} | tee {refold_log_file}\n",
        "echo \n",
        "echo Ranking...\n",
        "{rerank_sh_file} | tee {reranking_log_file}\n",
        "\"\"\"\n",
        "pipeline_cmd += f\"\"\"\n",
        "echo \n",
        "echo Job done\n",
        "echo {JOB_FOLDER}\n",
        "\"\"\"\n",
        "with open(pipeline_sh_file,'w') as pipeline_sh:\n",
        "    pipeline_sh.write(pipeline_cmd)\n",
        "os.chmod(pipeline_sh_file, 0o755) #Give execution rights\n",
        "pipeline_backup_sh_file = os.path.join(BASH_FOLDER,\"pipeline.sh\")\n",
        "shutil.copy(pipeline_sh_file,pipeline_backup_sh_file)\n",
        "\n",
        "batch_sh_file = os.path.join(PIPELINES_FOLDER,\"rfd_batch.sh\")\n",
        "if not ONE_JOB and os.path.exists(batch_sh_file):\n",
        "    with open(batch_sh_file,\"r\") as rfd_batch_sh:\n",
        "        previous_pipelines = rfd_batch_sh.readlines()\n",
        "    with open(batch_sh_file,\"w\") as rfd_batch_sh:\n",
        "        rfd_batch_sh.writelines(previous_pipelines)\n",
        "        rfd_batch_sh.write(\"\\n\")\n",
        "        rfd_batch_sh.write(pipeline_sh_file)  \n",
        "else:      \n",
        "    with open(batch_sh_file,\"w\") as rfd_batch_sh:\n",
        "        rfd_batch_sh.write(pipeline_sh_file)  \n",
        "os.chmod(batch_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "print(\"Run using next cell\")\n",
        "print(f\"Single job:\\n{pipeline_sh_file}\\nor\\n{pipeline_backup_sh_file}\")\n",
        "print(f\"Batch:\\n{batch_sh_file}\")\n",
        "print(f\"\\nOutput of this pipeline will be in:\\n{JOB_FOLDER}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "RFdiffusion-AllAtom can only be used via SlurmFiles\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MAKE SLURM FILE\n",
        "\"\"\"\n",
        "PACKAGE_MANAGER = \"mamba\"\n",
        "GPU = \"gpu\" #options: \"gpu\" (first available), \"t4\", \"v100\", \"v100-32g\", \"a100\"\n",
        "\n",
        "slurm_file = unique_name(PIPELINES_FOLDER,\"rfd_slurm\",\".sh\",1)\n",
        "with open(batch_sh_file,\"r\") as rfd_batch_sh:\n",
        "    all_pipelines = rfd_batch_sh.readlines()\n",
        "with open(slurm_file,\"w\") as slurm_bash:\n",
        "    slurm_bash.write(f\"module load {PACKAGE_MANAGER}\\n\")\n",
        "    slurm_bash.write(f\"module load {GPU}\\n\")\n",
        "    slurm_bash.write(f\"module load singularityce\\n\")\n",
        "    slurm_bash.writelines(all_pipelines)\n",
        "os.chmod(slurm_file, 0o755)\n",
        "\n",
        "print(f\"\"\"\n",
        "ScienceApps > Jobs > JobComposer > New Job > From Default Template    \n",
        "Edit Job name from Job Options.\n",
        "Replace job.sh (Open in Editor) with the following (adapt required time hh:mm:ss) then Save:\n",
        "      \n",
        "#!/usr/bin/bash\n",
        "#SBATCH --gpus=1\n",
        "#SBATCH --mem=7800\n",
        "#SBATCH --time=23:59:00\n",
        "#SBATCH --output=job.out      \n",
        "{slurm_file}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Conventions for names\n",
        "Paths to files end with _type_file\n",
        "Paths to folders end with _FOLDER\n",
        "Opened files .type end with _type\n",
        "Content of .sh end with _cmd\n",
        "Content of .py end with _script\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Cleanup instructions\n",
        "Delete data/bash_files\n",
        "Delete outputs folder: contains log files\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQXlWEjIOsf"
      },
      "source": [
        "**Instructions**\n",
        "---\n",
        "---\n",
        "\n",
        "Use `contigs` to define continious chains. Use a `:` to define multiple contigs and a `/` to define mutliple segments within a contig.\n",
        "For example:\n",
        "\n",
        "**unconditional**\n",
        "- `contigs='100'` - diffuse **monomer** of length 100\n",
        "- `contigs='50:100'` - diffuse **hetero-oligomer** of lengths 50 and 100\n",
        "- `contigs='50'` `symmetry='cyclic'` `order=2` - make two copies of the defined contig(s) and add a symmetry constraint, for **homo-oligomeric** diffusion.\n",
        "\n",
        "**binder design**\n",
        "- `contigs='A:50'` `pdb='4N5T'` - diffuse a **binder** of length 50 to chain A of defined PDB.\n",
        "- `contigs='E6-155:70-100'` `pdb='5KQV'` `hotspot='E64,E88,E96'` - diffuse a **binder** of length 70 to 100 (sampled randomly) to chain E and defined hotspot(s).\n",
        "\n",
        "**motif scaffolding**\n",
        " - `contigs='40/A163-181/40'` `pdb='5TPN'`\n",
        " - `contigs='A3-30/36/A33-68'` `pdb='6MRR'` - diffuse a loop of length 36 between two segments of defined PDB ranges.\n",
        "\n",
        "**partial diffusion**\n",
        "- `contigs=''` `pdb='6MRR'` - noise all coordinates\n",
        "- `contigs='A1-10'` `pdb='6MRR'` - keep first 10 positions fixed, noise the rest\n",
        "- `contigs='A'` `pdb='1SSC'` - fix chain A, noise the rest\n",
        "\n",
        "*hints and tips*\n",
        "- `pdb=''` leave blank to get an upload prompt\n",
        "- `contigs='50-100'` use dash to specify a range of lengths to sample from"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
