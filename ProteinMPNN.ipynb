{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Copyright © 2024 LOCBP @ University of Zürich\n",
        "#Distributed under MIT license\n",
        "\n",
        "APPEND_JOB = False\n",
        "\"\"\"\n",
        "INPUT PARAMETERS\n",
        "\"\"\"\n",
        "\"\"\"ProteinMPNN\"\"\"\n",
        "NAME = \"\" #if empty, the name will be the PDB #No whitespaces\n",
        "PDB = \"\" #pdb (upload not implemented) or pdb folder containing folded proteins\n",
        "NUM_SEQ = 1\n",
        "FIXED = \"\" #pymol-formatted selection e.g. \"10-15+17+20-54\". Incompatible with pLDDT_THRESHOLD when a folder is given as input\n",
        "FIXED_CHAIN = \"A\" #To be implemented: possibility to fix more than one chain\n",
        "pLDDT_THRESHOLD = 100 #Will consider residues with pLDDT >= threshold as fixed. Only if pLDDT is stored in b values of the protein, so input must be from AlphaFold or OmegaFold\n",
        "#Advanced\n",
        "SAMPLING_T = \"0.1\"\n",
        "\"\"\"FOLD\"\"\"\n",
        "FOLD = \"AF\" #Choices are AF for AlphaFold and OF for OmegaFold\n",
        "#AlphaFold\n",
        "#Advanced\n",
        "NUM_RELAX = 0 #How many of the best-ranked models do you want to relax with amber?\n",
        "NUM_RECYCLE = 3 #Default (and recommended) is 3\n",
        "RAND_SEED = 0\n",
        "ONLY_FIRST = True #Only compare the best folding of each sequence generated\n",
        "#OmegaFold\n",
        "MODEL = 2 #Model 2 can only be used with V100-32GB or A100-80GB\n",
        "#Ranking\n",
        "METRIC = \"pLDDT\" #\"pLDDT\" or \"pTM\" or \"RMSD\". pTM not available in omegafold\n",
        "RMSD_ALIGNMENT = 'cealign' #'cealign' or 'align' or 'super' or 'fit'\n",
        "PYMOL_BEST = 10 #Create a pymol session contaning the N best models aligned with the original protein and colored by pLDDT\n",
        "#DNA\n",
        "DNA=True #Generates DNA sequences for Homo Sapiens and E coli\n",
        "\n",
        "\"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "#Quick refinement of input\n",
        "ONE_JOB = not APPEND_JOB\n",
        "if FOLD == \"AF\": FOLD = \"AlphaFold\"\n",
        "elif FOLD == \"OF\": FOLD = \"OmegaFold\"\n",
        "if FIXED == \"\":\n",
        "    FIXED = \"-\"\n",
        "    \n",
        "import os,shutil #WE USE ABSOLUTE PATHS\n",
        "#CUDA\n",
        "ENVIRONMENT = \"ProteinEnv\"\n",
        "#General\n",
        "MODELS_OUTPUT_FOLDER = \"scratch\" #Where to store output (subfolders will be created inside)\n",
        "INSTALLATION_FOLDER = \"data\"\n",
        "#GENERAL FOLDERS\n",
        "NOTEBOOKS_FOLDER = os.getcwd()\n",
        "PIPELINES_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"Pipelines\")\n",
        "PDBs_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"PDBs\")\n",
        "HELP_FOLDER = os.path.join(NOTEBOOKS_FOLDER,\"HelpScripts\")\n",
        "USER_NAME = os.path.basename(os.path.dirname(NOTEBOOKS_FOLDER))\n",
        "HOME_FOLDER = f\"/home/{USER_NAME}\"\n",
        "DATA_FOLDER = f\"/data/{USER_NAME}\"\n",
        "SCRATCH_FOLDER = f\"/scratch/{USER_NAME}\"\n",
        "#MODIFIABLE FOLDERS\n",
        "INSTALLATION_FOLDER = DATA_FOLDER\n",
        "MODELS_OUTPUT_FOLDER = os.path.join(SCRATCH_FOLDER,\"ProteinOutput\")\n",
        "if not os.path.exists(MODELS_OUTPUT_FOLDER):\n",
        "    os.mkdir(MODELS_OUTPUT_FOLDER)\n",
        "#MODELS\n",
        "PMPNN_FOLDER = os.path.join(INSTALLATION_FOLDER,\"ProteinMPNN\")\n",
        "COLAB_FOLD_FOLDER = os.path.join(INSTALLATION_FOLDER,\"localcolabfold\")\n",
        "OMEGA_FOLDER = os.path.join(INSTALLATION_FOLDER,\"OmegaFold\")\n",
        "OUT_FOLDER = os.path.join(MODELS_OUTPUT_FOLDER,\"ProteinMPNN\")\n",
        "if not os.path.exists(OUT_FOLDER):\n",
        "    os.mkdir(OUT_FOLDER)\n",
        "\n",
        "#This will be used throughout to generate file and directory names to avoid overriding old outputs\n",
        "def unique_name(directory,root,ext = \"\",fullpath=0,w=3):   \n",
        "    i = 1     \n",
        "    u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    while os.path.exists(os.path.join(directory,u_name+ext)):\n",
        "        i += 1\n",
        "        u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    if fullpath: return os.path.join(directory, u_name + ext)\n",
        "    return u_name + ext\n",
        "\n",
        "\"\"\"\n",
        "SET JOB NAME AND CREATE OUTPUT DIRECTORIES\n",
        "Data are stored in the \"PMPNN_output\" folder inside the data folder\n",
        "Also, a folder containg all the results is created inside that folder\n",
        "\"\"\"\n",
        "JOB_BASE = NAME if NAME != \"\" else os.path.splitext(os.path.basename(PDB))[0]\n",
        "JOB = unique_name(OUT_FOLDER,JOB_BASE)\n",
        "JOB_FOLDER = os.path.join(OUT_FOLDER,JOB)\n",
        "os.mkdir(JOB_FOLDER)\n",
        "RUNTIME_FOLDER = os.path.join(JOB_FOLDER,\"RunTime\")\n",
        "if not os.path.exists(RUNTIME_FOLDER):\n",
        "    os.mkdir(RUNTIME_FOLDER)\n",
        "#Output from console will also be redirected to log files\n",
        "pmpnn_log_file = os.path.join(JOB_FOLDER,\"_pmpnn.log\")\n",
        "fold_log_file = os.path.join(JOB_FOLDER,f\"_{FOLD}.log\")\n",
        "ranking_log_file = os.path.join(JOB_FOLDER,\"_ranking.log\")\n",
        "dna_log_file = os.path.join(JOB_FOLDER,\"_dna.log\")\n",
        "\n",
        "\"\"\"ProteinMPNN\"\"\"\n",
        "#Parse folder for multiple pdb input\n",
        "parsed_pdbs_jsonl_file = os.path.join(RUNTIME_FOLDER,f\"{JOB}_parsed_pdbs.jsonl\")\n",
        "parse_py_file = os.path.join(PMPNN_FOLDER,\"helper_scripts/parse_multiple_chains.py\")\n",
        "fixed_jsonl_file = os.path.join(RUNTIME_FOLDER,f\"{JOB}_fixed_pos.jsonl\")\n",
        "sele_csv_file = os.path.join(RUNTIME_FOLDER,\"pmpnn_sele.csv\")\n",
        "\n",
        "pdb_temp = PDB if PDB.endswith(\".pdb\") else PDB + \".pdb\"\n",
        "pdb_temp_file = os.path.join(PDBs_FOLDER,pdb_temp)\n",
        "if os.path.exists(pdb_temp_file): #PDB is a file\n",
        "    pdb_file = os.path.join(RUNTIME_FOLDER,pdb_temp)\n",
        "    shutil.copy(pdb_temp_file,pdb_file)\n",
        "else: #otherwise it is a folder\n",
        "    pdb_folder = os.path.join(os.getcwd(),PDB)\n",
        "    if os.path.exists(pdb_folder):\n",
        "        pdb_files = [pdb for pdb in os.listdir(pdb_folder) if pdb.endswith(\".pdb\")]\n",
        "        for pdb_file in pdb_files:\n",
        "            new_pdb_file = os.path.join(RUNTIME_FOLDER,pdb_file)\n",
        "            shutil.copy(os.path.join(pdb_folder,pdb_file),new_pdb_file)\n",
        "\n",
        "#IMPLEMENTATION OF FIXED POSITIONS\n",
        "fixed_py_file = os.path.join(HELP_FOLDER,\"make_fixed_dict.py\")\n",
        "\n",
        "#Set options\n",
        "pmpnn_options = f\"--num_seq_per_target {NUM_SEQ}\"\n",
        "pmpnn_options += f\" --sampling_temp {SAMPLING_T}\"\n",
        "pmpnn_py_file = os.path.join(PMPNN_FOLDER,\"protein_mpnn_run.py\")\n",
        "\n",
        "pmpnn_sh_file = unique_name(RUNTIME_FOLDER,\"pmpnn\",\".sh\",1)\n",
        "pmpnn_cmd = f\"\"\"\n",
        "echo Determining fixed positions\n",
        "python {fixed_py_file} {RUNTIME_FOLDER} norfd {pLDDT_THRESHOLD} {FIXED} {FIXED_CHAIN} {fixed_jsonl_file} {sele_csv_file}\n",
        "echo Parsing multiple pbds \n",
        "python {parse_py_file} --input_path {RUNTIME_FOLDER} --output_path {parsed_pdbs_jsonl_file}\n",
        "echo Running model\n",
        "python {pmpnn_py_file} --jsonl_path {parsed_pdbs_jsonl_file} --fixed_positions_jsonl {fixed_jsonl_file} --out_folder {JOB_FOLDER} {pmpnn_options}\n",
        "\"\"\"\n",
        "with open(pmpnn_sh_file,'w') as pmpnn_sh:\n",
        "    pmpnn_sh.write(pmpnn_cmd)\n",
        "os.chmod(pmpnn_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"FOLD\"\"\"\n",
        "FOLD_OUT_FOLDER = os.path.join(JOB_FOLDER,FOLD)\n",
        "if not os.path.exists(FOLD_OUT_FOLDER):\n",
        "    os.mkdir(FOLD_OUT_FOLDER)\n",
        "PMPNN_FA_FOLDER = os.path.join(JOB_FOLDER,\"seqs\") #This is the folder where pmpnn outputs fasta files\n",
        "queries_csv_file = os.path.join(RUNTIME_FOLDER,\"queries.csv\") #These will contain the queries\n",
        "queries_fasta_file = os.path.join(JOB_FOLDER,\"queries.fasta\")\n",
        "fa_to_csv_fasta_py_file = os.path.join(HELP_FOLDER,\"fa_to_csv_fasta.py\")\n",
        "\n",
        "fold_sh_file = \"\"\n",
        "if FOLD == \"AlphaFold\":\n",
        "    af2_options = \"\"\n",
        "    if NUM_RELAX > 0: af2_options += f\" --amber --use-gpu-relax --num-relax {NUM_RELAX}\" #assumed to run on GPU\n",
        "    if NUM_RECYCLE != 3: af2_options += f\" --num-recycle {NUM_RECYCLE}\"\n",
        "    if RAND_SEED != 0: af2_options += f\" --random-seed {RAND_SEED}\"\n",
        "\n",
        "    colabfold_batch_file = os.path.join(COLAB_FOLD_FOLDER,\"colabfold-conda/bin/colabfold_batch\")\n",
        "    fold_sh_file = unique_name(RUNTIME_FOLDER,\"alphafold\",\".sh\",1)\n",
        "    af2_cmd = f\"\"\"\n",
        "    echo Generating queries.csv file from .fa output\n",
        "    python {fa_to_csv_fasta_py_file} {PMPNN_FA_FOLDER} {queries_csv_file} {queries_fasta_file}\n",
        "    echo Initializing model...\n",
        "    {colabfold_batch_file} {queries_csv_file} {FOLD_OUT_FOLDER} {af2_options}\n",
        "    \"\"\"\n",
        "    with open(fold_sh_file,'w') as af2_sh:\n",
        "        af2_sh.write(af2_cmd)\n",
        "elif FOLD == \"OmegaFold\":\n",
        "    of_options = \"\"\n",
        "    of_options += f\" --model {MODEL}\"\n",
        "    weights_pt = [\"\",\"release1.pt\",\"release2.pt\"][MODEL]\n",
        "    weights_pt_file = os.path.join(OMEGA_FOLDER,weights_pt)\n",
        "    of_options += f\" --weights_file {weights_pt_file}\"\n",
        "    fold_sh_file = unique_name(RUNTIME_FOLDER,\"omegafold\",\".sh\",1)\n",
        "    of_cmd = f\"\"\"\n",
        "    echo Generating queries.csv file from .fa output\n",
        "    python {fa_to_csv_fasta_py_file} {PMPNN_FA_FOLDER} {queries_csv_file} {queries_fasta_file}\n",
        "    echo Initializing model...\n",
        "    omegafold {queries_fasta_file} {FOLD_OUT_FOLDER} {of_options}\n",
        "    \"\"\"\n",
        "    with open(fold_sh_file,'w') as of_sh:\n",
        "        of_sh.write(of_cmd)\n",
        "os.chmod(fold_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"RANK EVERYTHING\"\"\"\n",
        "rank_pdb = pdb_file if pdb_file != \"\" else \"-\"\n",
        "rank_output_csv_file = os.path.join(JOB_FOLDER,JOB_BASE+\".csv\")\n",
        "rank_best_fasta_file = os.path.join(JOB_FOLDER,JOB_BASE+f\"_Best{PYMOL_BEST}.fasta\")\n",
        "rank_pse_file = os.path.join(JOB_FOLDER,JOB_BASE+f\"_{FOLD}.pse\")\n",
        "rank_py_file = os.path.join(HELP_FOLDER,f\"rank_{FOLD}.py\")\n",
        "rank_cmd = f\"python {rank_py_file} {fold_log_file} {queries_csv_file} {NUM_SEQ} {sele_csv_file} {FOLD_OUT_FOLDER} {rank_pdb} {rank_output_csv_file} {METRIC} {RMSD_ALIGNMENT} {rank_pse_file} {PYMOL_BEST} {rank_best_fasta_file} {ONLY_FIRST}\"\n",
        "rank_sh_file = unique_name(RUNTIME_FOLDER,f\"rank_{FOLD}\",\".sh\",1)\n",
        "with open(rank_sh_file,'w') as rank_sh:\n",
        "    rank_sh.write(rank_cmd)\n",
        "os.chmod(rank_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"DNA\"\"\"\n",
        "DNA_FOLDER=os.path.join(JOB_FOLDER,\"DNA\")\n",
        "if not os.path.exists(DNA_FOLDER):\n",
        "    os.mkdir(DNA_FOLDER)\n",
        "dna_prefix = os.path.join(DNA_FOLDER,JOB_BASE)\n",
        "dna_encoder_py_file = os.path.join(HELP_FOLDER,\"dna_encoder.py\")\n",
        "dna_encoder_cmd = f\"python {dna_encoder_py_file} {rank_best_fasta_file} {dna_prefix}\"\n",
        "dna_encoder_sh_file = os.path.join(RUNTIME_FOLDER,\"dna_encoder.sh\")\n",
        "with open(dna_encoder_sh_file,'w') as dna_encoder_sh:\n",
        "    dna_encoder_sh.write(dna_encoder_cmd)\n",
        "os.chmod(dna_encoder_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"COMBINE ALL IN A UNIQUE PIPELINE\"\"\"\n",
        "pipeline_sh_file = unique_name(RUNTIME_FOLDER,\"pipeline\",\".sh\",1)\n",
        "print_options_cmd = f\"\"\"\n",
        "echo Pipeline: {os.path.basename(pipeline_sh_file)}\n",
        "echo\n",
        "echo Name: {NAME}\n",
        "echo PDB: {PDB}\n",
        "\n",
        "\n",
        "echo ProteinMPNN\n",
        "echo   NUM SEQUENCES PER TARGET: {NUM_SEQ}\n",
        "echo   FIXED: {FIXED}\n",
        "echo   FIXED CHAIN: {FIXED_CHAIN} \n",
        "echo   pLDDT THR: {pLDDT_THRESHOLD}\n",
        "echo   SAMPLING T: {SAMPLING_T}\n",
        "echo\n",
        "echo FOLD MODEL: {FOLD}\n",
        "echo   AlphaFold\n",
        "echo     NUM RELAX: {NUM_RELAX}\n",
        "echo     NUM RECYCLE: {NUM_RECYCLE}\n",
        "echo     RANDOM GENERATOR SEED: {RAND_SEED}\n",
        "echo   OmegaFold\n",
        "echo     MODEL: {MODEL}\n",
        "echo\n",
        "echo \"Alignment algorithm: {RMSD_ALIGNMENT}\"\n",
        "\"\"\"\n",
        "pipeline_cmd = print_options_cmd + f\"\"\"\n",
        "source activate {ENVIRONMENT}\n",
        "echo\n",
        "echo ProteinMPNN\n",
        "{pmpnn_sh_file} | tee {pmpnn_log_file}\n",
        "echo\n",
        "echo {FOLD}\n",
        "{fold_sh_file} | tee {fold_log_file}\n",
        "echo \n",
        "echo Ranking...\n",
        "{rank_sh_file} | tee {ranking_log_file}\"\"\"\n",
        "if DNA: pipeline_cmd += f\"\"\"\n",
        "echo\n",
        "echo DNA\n",
        "{dna_encoder_sh_file} | tee {dna_log_file}\n",
        "\"\"\"\n",
        "pipeline_cmd += f\"\"\"\n",
        "echo \n",
        "echo Job done\n",
        "echo {JOB_FOLDER}\n",
        "\"\"\"\n",
        "with open(pipeline_sh_file,'w') as pipeline_sh:\n",
        "    pipeline_sh.write(pipeline_cmd)\n",
        "os.chmod(pipeline_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "batch_sh_file = os.path.join(PIPELINES_FOLDER,\"pmpnn_batch.sh\")\n",
        "if not ONE_JOB and os.path.exists(batch_sh_file):\n",
        "    with open(batch_sh_file,\"r\") as pmpnn_batch_sh:\n",
        "        previous_pipelines = pmpnn_batch_sh.readlines()\n",
        "    with open(batch_sh_file,\"w\") as pmpnn_batch_sh:\n",
        "        pmpnn_batch_sh.writelines(previous_pipelines)\n",
        "        pmpnn_batch_sh.write(\"\\n\")\n",
        "        pmpnn_batch_sh.write(pipeline_sh_file)  \n",
        "else:      \n",
        "    with open(batch_sh_file,\"w\") as pmpnn_batch_sh:\n",
        "        pmpnn_batch_sh.write(pipeline_sh_file)  \n",
        "os.chmod(batch_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "#write configuration file\n",
        "config_txt_file = os.path.join(JOB_FOLDER,JOB_BASE+\"_config.txt\")\n",
        "with open(config_txt_file,'w') as config_txt:\n",
        "    config_txt.write(print_options_cmd)\n",
        "\n",
        "print(\"Run using next cell\")\n",
        "print(f\"Single job:\\n{pipeline_sh_file}\")\n",
        "print(f\"Batch:\\n{batch_sh_file}\")\n",
        "print(f\"\\nOutput of this pipeline will be in:\\n{JOB_FOLDER}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "/home/$USER/ProteinNotebooks/Pipelines/pmpnn_batch.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MAKE SLURM FILE\n",
        "\"\"\"\n",
        "PACKAGE_MANAGER = \"mamba\"\n",
        "GPU = \"A100\" \n",
        "\"\"\"\n",
        "GPUs available are:\n",
        "T4      0.022 CHF/h\n",
        "V100    0.057 CHF/h\n",
        "A100    0.081 CHF/h\n",
        "These can be allocated by setting GPU = \"T4\", \"V100\", or \"A100\"\n",
        "By setting GPU=\"gpu\", the first available will be used\n",
        "By setting GPU=\"high-memory\", either v100-32gb or a100 are selected. \n",
        "Important: OmegaFold model 2 only works with high-memory GPUs. Sometimes it fails with 32G as well, so it is safer to use A100\n",
        "\"\"\"\n",
        "\n",
        "slurm_file = unique_name(PIPELINES_FOLDER,\"pmpnn_slurm\",\".sh\",1)\n",
        "with open(batch_sh_file,\"r\") as rfd_batch_sh:\n",
        "    all_pipelines = rfd_batch_sh.readlines()\n",
        "with open(slurm_file,\"w\") as slurm_bash:\n",
        "    slurm_bash.write(\"\"\"# Check if nvidia-smi is available\n",
        "if ! command -v nvidia-smi &> /dev/null\n",
        "then\n",
        "    echo \"Could not load GPU correctly: nvidia-smi could not be found\"\n",
        "    exit\n",
        "fi\n",
        "gpu_type=$(nvidia-smi --query-gpu=gpu_name --format=csv,noheader)\n",
        "echo \"GPU Type: $gpu_type\"\\n\n",
        "\"\"\")\n",
        "    slurm_bash.write(f\"module load {PACKAGE_MANAGER}\\n\")\n",
        "    slurm_bash.writelines(all_pipelines)\n",
        "os.chmod(slurm_file, 0o755)\n",
        "\n",
        "if GPU == \"high-memory\":\n",
        "    gpu_line = \"#SBATCH --gpus=1\\n#SBATCH --constraint=\\\"GPUMEM32GB|GPUMEM80GB\\\"\"\n",
        "elif GPU == \"gpu\":\n",
        "    gpu_line = \"#SBATCH --gpus=1\"\n",
        "else:\n",
        "    gpu_line = f\"#SBATCH --gpus={GPU}:1\"\n",
        "\n",
        "\n",
        "job_comps=JOB_FOLDER.split('/')\n",
        "job_name=f\"{job_comps[-2]}: {job_comps[-1]}\"\n",
        "\n",
        "print(f\"\"\"\n",
        "ScienceApps > Jobs > JobComposer > New Job > From Default Template    \n",
        "Edit Job name from Job Options. Suggested:\n",
        "\n",
        "{job_name}       \n",
        "\n",
        "Replace job.sh (Open in Editor) with the following (adapt required time hh:mm:ss) then Save:\n",
        "      \n",
        "#!/usr/bin/bash\n",
        "{gpu_line}\n",
        "#SBATCH --mem=7800\n",
        "#SBATCH --time=23:59:00\n",
        "#SBATCH --output=job.out      \n",
        "{slurm_file}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Conventions for names\n",
        "Paths to files end with _type_file\n",
        "Paths to folders end with _FOLDER\n",
        "Opened files .type end with _type\n",
        "Content of .sh end with _cmd\n",
        "Content of .py end with _script\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Cleanup instructions\n",
        "Delete data/bash_files\n",
        "Delete outputs folder: contains log files\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
