{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "APPEND_JOB = False\n",
        "\"\"\"\n",
        "INPUT PARAMETERS\n",
        "\"\"\"\n",
        "#ProteinMPNN\n",
        "NAME = \"test\" #if empty, the name will be the PDB\n",
        "PDB = \"\" #pdb (upload not implemented) or pdb folder containing folded proteins\n",
        "NUM_SEQ = 1\n",
        "FIXED = \"\" #pymol-formatted selection e.g. \"10-15+17+20-54\". Incompatible with pLDDT_THRESHOLD! Especially with folder input\n",
        "FIXED_CHAIN = \"A\" #To be implemented: possibility to fix more than one chain\n",
        "pLDDT_THRESHOLD = 100 #Only if input pdbs were generated with alphafold. Will consider residues with pLDDT >= threshold as fixed \n",
        "#Advanced\n",
        "SAMPLING_T = \"0.1\"\n",
        "#AlphaFold\n",
        "#Advanced\n",
        "NUM_RELAX = 0 #How many of the best-ranked models do you want to relax with amber?\n",
        "NUM_RECYCLE = 3 #Default (and recommended) is 3\n",
        "RAND_SEED = 0\n",
        "#Ranking\n",
        "METRIC = \"pLDDT\" #\"pLDDT\" or \"pTM\" or \"RMSD\"\n",
        "PYMOL_BEST = 10 #Create a pymol session contaning the N best models aligned with the original protein and colored by pLDDT\n",
        "ONLY_FIRST = True #Only compare the best folding of each sequence generated\n",
        "#General\n",
        "DATA_FOLDER = \"scratch\" #Where to store output (subfolders will be created inside)\n",
        "PIPELINES_FOLDER = \"data/pipelines\"\n",
        "INSTALLATION_FOLDER = \"data\"\n",
        "ENVIRONMENT = \"ProteinEnv\"\n",
        "\n",
        "\"\"\"\n",
        "CODE\n",
        "\"\"\"\n",
        "ONE_JOB = not APPEND_JOB\n",
        "import os, shutil\n",
        "#WE USE ABSOLUTE PATHS\n",
        "DATA_FOLDER = os.path.join(os.getcwd(),DATA_FOLDER)\n",
        "PIPELINES_FOLDER = os.path.join(os.getcwd(),PIPELINES_FOLDER)\n",
        "INSTALLATION_FOLDER = os.path.join(os.getcwd(),INSTALLATION_FOLDER)\n",
        "COLAB_FOLD_FOLDER = os.path.join(INSTALLATION_FOLDER,\"localcolabfold\")\n",
        "PMPNN_FOLDER = os.path.join(INSTALLATION_FOLDER,\"ProteinMPNN\")\n",
        "HELP_FOLDER = os.path.join(INSTALLATION_FOLDER,\"HelpScripts\")\n",
        "#CREATE FOLDERS FOR BASH FILES AND DIFFUSION OUTPUT\n",
        "if not os.path.exists(PIPELINES_FOLDER):\n",
        "    os.mkdir(PIPELINES_FOLDER)\n",
        "OUT_FOLDER = os.path.join(DATA_FOLDER,\"PMPNN_output\")\n",
        "if not os.path.exists(OUT_FOLDER):\n",
        "    os.mkdir(OUT_FOLDER)\n",
        "\n",
        "#This will be used throughout to generate file and directory names to avoid overriding old outputs\n",
        "def unique_name(directory,root,ext = \"\",fullpath=0,w=3):   \n",
        "    i = 1     \n",
        "    u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    while os.path.exists(os.path.join(directory,u_name+ext)):\n",
        "        i += 1\n",
        "        u_name = root + \"_\" + \"{:0>{width}}\".format(i, width=w)\n",
        "    if fullpath: return os.path.join(directory, u_name + ext)\n",
        "    return u_name + ext\n",
        "\n",
        "\"\"\"\n",
        "SET JOB NAME AND CREATE OUTPUT DIRECTORIES\n",
        "Data are stored in the \"PMPNN_output\" folder inside the data folder\n",
        "Also, a folder containg all the results is created inside that folder\n",
        "\"\"\"\n",
        "JOB_BASE = NAME if NAME != \"\" else os.path.splitext(os.path.basename(PDB))[0]\n",
        "JOB = unique_name(OUT_FOLDER,JOB_BASE)\n",
        "JOB_FOLDER = os.path.join(OUT_FOLDER,JOB)\n",
        "os.mkdir(JOB_FOLDER)\n",
        "BASH_FOLDER = os.path.join(JOB_FOLDER,\"bash_files\")\n",
        "if not os.path.exists(BASH_FOLDER):\n",
        "    os.mkdir(BASH_FOLDER)\n",
        "#Output from consol will also be redirected to log files\n",
        "pmpnn_log_file = os.path.join(JOB_FOLDER,\"pmpnn.log\")\n",
        "af2_log_file = os.path.join(JOB_FOLDER,\"af2.log\")\n",
        "ranking_log_file = os.path.join(JOB_FOLDER,\"ranking.log\")\n",
        "\n",
        "\"\"\"ProteinMPNN\"\"\"\n",
        "#Parse folder for multiple pdb input\n",
        "parsed_pdbs_jsonl_file = os.path.join(JOB_FOLDER,f\"{JOB}_parsed_pdbs.jsonl\")\n",
        "parse_py_file = os.path.join(PMPNN_FOLDER,\"helper_scripts/parse_multiple_chains.py\")\n",
        "fixed_jsonl_file = os.path.join(JOB_FOLDER,f\"{JOB}_fixed_pos.jsonl\")\n",
        "sele_csv_file = os.path.join(JOB_FOLDER,\"pmpnn_sele.csv\")\n",
        "\n",
        "pdb_temp = PDB if PDB.endswith(\".pdb\") else PDB + \".pdb\"\n",
        "if os.path.exists(pdb_temp): #PDB is a file\n",
        "    pdb_file = os.path.join(BASH_FOLDER,pdb_temp)\n",
        "    shutil.copy(pdb_temp,pdb_file)\n",
        "else: #otherwise it is a folder\n",
        "    pdb_folder = os.path.join(os.getcwd(),PDB)\n",
        "    if os.path.exists(pdb_folder):\n",
        "        pdb_files = [pdb for pdb in os.listdir(pdb_folder) if pdb.endswith(\".pdb\")]\n",
        "        for pdb_file in pdb_files:\n",
        "            new_pdb_file = os.path.join(BASH_FOLDER,pdb_file)\n",
        "            shutil.copy(os.path.join(pdb_folder,pdb_file),new_pdb_file)\n",
        "\n",
        "#IMPLEMENTATION OF FIXED POSITIONS\n",
        "fixed_py_file = os.path.join(HELP_FOLDER,\"make_fixed_dict.py\")\n",
        "\n",
        "#Set options\n",
        "pmpnn_options = f\"--num_seq_per_target {NUM_SEQ}\"\n",
        "pmpnn_options += f\" --sampling_temp {SAMPLING_T}\"\n",
        "pmpnn_py_file = os.path.join(PMPNN_FOLDER,\"protein_mpnn_run.py\")\n",
        "\n",
        "pmpnn_sh_file = unique_name(BASH_FOLDER,\"pmpnn\",\".sh\",1)\n",
        "pmpnn_cmd = f\"\"\"\n",
        "echo Determining fixed positions\n",
        "python {fixed_py_file} {BASH_FOLDER} norfd {pLDDT_THRESHOLD} {FIXED} {FIXED_CHAIN} {fixed_jsonl_file} {sele_csv_file}\n",
        "echo Parsing multiple pbds \n",
        "python {parse_py_file} --input_path {BASH_FOLDER} --output_path {parsed_pdbs_jsonl_file}\n",
        "echo Running model\n",
        "python {pmpnn_py_file} --jsonl_path {parsed_pdbs_jsonl_file} --fixed_positions_jsonl {fixed_jsonl_file} --out_folder {JOB_FOLDER} {pmpnn_options}\n",
        "\"\"\"\n",
        "with open(pmpnn_sh_file,'w') as pmpnn_sh:\n",
        "    pmpnn_sh.write(pmpnn_cmd)\n",
        "os.chmod(pmpnn_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"ALPHAFOLD\"\"\"\n",
        "AF2_OUT_FOLDER = os.path.join(JOB_FOLDER,\"AF2\")\n",
        "if not os.path.exists(AF2_OUT_FOLDER):\n",
        "    os.mkdir(AF2_OUT_FOLDER)\n",
        "PMPNN_FA_FOLDER = os.path.join(JOB_FOLDER,\"seqs\") #This is the folder where pmpnn outputs fasta files\n",
        "queries_csv_file = os.path.join(JOB_FOLDER,\"af2_queries.csv\") #This will contain the queries\n",
        "fa_to_csv_py_file = os.path.join(HELP_FOLDER,\"fa_to_csv.py\")\n",
        "\n",
        "af2_options = \"\"\n",
        "if NUM_RELAX > 0: af2_options += f\" --amber --use-gpu-relax --num-relax {NUM_RELAX}\" #assumed to run on GPU\n",
        "if NUM_RECYCLE != 3: af2_options += f\" --num-recycle {NUM_RECYCLE}\"\n",
        "if RAND_SEED != 0: af2_options += f\" --random-seed {RAND_SEED}\"\n",
        "\n",
        "colabfold_batch_file = os.path.join(COLAB_FOLD_FOLDER,\"colabfold-conda/bin/colabfold_batch\")\n",
        "af2_sh_file = unique_name(BASH_FOLDER,\"pmpnn_af2\",\".sh\",1)\n",
        "af2_cmd = f\"\"\"\n",
        "echo Generating queries.csv file from .fa output\n",
        "python {fa_to_csv_py_file} {PMPNN_FA_FOLDER} {queries_csv_file}\n",
        "echo Initializing model...\n",
        "{colabfold_batch_file} {queries_csv_file} {AF2_OUT_FOLDER} {af2_options}\n",
        "\"\"\"\n",
        "with open(af2_sh_file,'w') as af2_sh:\n",
        "    af2_sh.write(af2_cmd)\n",
        "os.chmod(af2_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"RANK EVERYTHING\"\"\"\n",
        "rank_pdb = pdb_file if pdb_file != \"\" else \"-\"\n",
        "rank_py_file = os.path.join(HELP_FOLDER,\"rank.py\")\n",
        "rank_output_csv_file = os.path.join(JOB_FOLDER,JOB_BASE+\".csv\")\n",
        "rank_pse_file = os.path.join(JOB_FOLDER,JOB_BASE+\".pse\")\n",
        "rank_cmd = f\"python {rank_py_file} {af2_log_file} {queries_csv_file} {NUM_SEQ} {sele_csv_file} {AF2_OUT_FOLDER} {rank_pdb} {rank_output_csv_file} {METRIC} {rank_pse_file} {PYMOL_BEST} {ONLY_FIRST}\"\n",
        "rank_sh_file = unique_name(BASH_FOLDER,\"pmpnn_af2_rank\",\".sh\",1)\n",
        "with open(rank_sh_file,'w') as rank_sh:\n",
        "    rank_sh.write(rank_cmd)\n",
        "os.chmod(rank_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "\"\"\"COMBINE ALL IN A UNIQUE PIPELINE\"\"\"\n",
        "pipeline_sh_file = unique_name(PIPELINES_FOLDER,\"pipeline\",\".sh\",1)\n",
        "pipeline_cmd = f\"\"\"\n",
        "echo Pipeline: {os.path.basename(pipeline_sh_file)}\n",
        "echo\n",
        "echo Name: {NAME}\n",
        "echo PDB: {PDB}\n",
        "echo FIXED: {FIXED}\n",
        "echo CHAIN: {FIXED_CHAIN}\n",
        "\n",
        "source activate {ENVIRONMENT}\n",
        "echo\n",
        "echo ProteinMPNN\n",
        "{pmpnn_sh_file} | tee {pmpnn_log_file}\n",
        "echo\n",
        "echo AlphaFold\n",
        "{af2_sh_file} | tee {af2_log_file}\n",
        "echo \n",
        "echo Ranking...\n",
        "{rank_sh_file} | tee {ranking_log_file}\n",
        "echo \n",
        "echo Job done\n",
        "echo {JOB_FOLDER}\n",
        "\"\"\"\n",
        "with open(pipeline_sh_file,'w') as pipeline_sh:\n",
        "    pipeline_sh.write(pipeline_cmd)\n",
        "os.chmod(pipeline_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "batch_sh_file = os.path.join(PIPELINES_FOLDER,\"pmpnn_batch.sh\")\n",
        "if not ONE_JOB and os.path.exists(batch_sh_file):\n",
        "    with open(batch_sh_file,\"r\") as pmpnn_batch_sh:\n",
        "        previous_pipelines = pmpnn_batch_sh.readlines()\n",
        "    with open(batch_sh_file,\"w\") as pmpnn_batch_sh:\n",
        "        pmpnn_batch_sh.writelines(previous_pipelines)\n",
        "        pmpnn_batch_sh.write(\"\\n\")\n",
        "        pmpnn_batch_sh.write(pipeline_sh_file)  \n",
        "else:      \n",
        "    with open(batch_sh_file,\"w\") as pmpnn_batch_sh:\n",
        "        pmpnn_batch_sh.write(pipeline_sh_file)  \n",
        "os.chmod(batch_sh_file, 0o755) #Give execution rights\n",
        "\n",
        "print(\"Run using next cell\")\n",
        "print(f\"Single job:\\n{pipeline_sh_file}\")\n",
        "print(f\"Batch:\\n{batch_sh_file}\")\n",
        "print(f\"\\nOutput of this pipeline will be in:\\n{JOB_FOLDER}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "/home/SIX-LETTERS-USER-NAME/data/pipelines/pmpnn_batch.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "MAKE SLURM FILE\n",
        "\"\"\"\n",
        "PACKAGE_MANAGER = \"mamba\"\n",
        "GPU = \"gpu\" #options: \"gpu\" (first available), \"t4\", \"v100\", \"v100-32g\", \"a100\"\n",
        "\n",
        "slurm_file = unique_name(PIPELINES_FOLDER,\"pmpnn_slurm\",\".sh\",1)\n",
        "with open(batch_sh_file,\"r\") as pmpnn_batch_sh:\n",
        "    all_pipelines = pmpnn_batch_sh.readlines()\n",
        "with open(slurm_file,\"w\") as slurm_bash:\n",
        "    slurm_bash.write(f\"module load {PACKAGE_MANAGER}\\n\")\n",
        "    slurm_bash.write(f\"module load {GPU}\\n\")\n",
        "    slurm_bash.writelines(all_pipelines)\n",
        "os.chmod(slurm_file, 0o755)\n",
        "\n",
        "print(f\"\"\"\n",
        "ScienceApps > Jobs > JobComposer > New Job > From Default Template    \n",
        "Edit Job name from Job Options.\n",
        "Replace job.sh (Open in Editor) with the following (adapt required time hh:mm:ss) then Save:\n",
        "      \n",
        "#!/usr/bin/bash\n",
        "#SBATCH --gpus=1\n",
        "#SBATCH --mem=7800\n",
        "#SBATCH --time=23:59:00\n",
        "#SBATCH --output=job.out      \n",
        "{slurm_file}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Conventions for names\n",
        "Paths to files end with _type_file\n",
        "Paths to folders end with _FOLDER\n",
        "Opened files .type end with _type\n",
        "Content of .sh end with _cmd\n",
        "Content of .py end with _script\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Cleanup instructions\n",
        "Delete data/bash_files\n",
        "Delete outputs folder: contains log files\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQXlWEjIOsf"
      },
      "source": [
        "**Instructions**\n",
        "---\n",
        "---\n",
        "\n",
        "Use `contigs` to define continious chains. Use a `:` to define multiple contigs and a `/` to define mutliple segments within a contig.\n",
        "For example:\n",
        "\n",
        "**unconditional**\n",
        "- `contigs='100'` - diffuse **monomer** of length 100\n",
        "- `contigs='50:100'` - diffuse **hetero-oligomer** of lengths 50 and 100\n",
        "- `contigs='50'` `symmetry='cyclic'` `order=2` - make two copies of the defined contig(s) and add a symmetry constraint, for **homo-oligomeric** diffusion.\n",
        "\n",
        "**binder design**\n",
        "- `contigs='A:50'` `pdb='4N5T'` - diffuse a **binder** of length 50 to chain A of defined PDB.\n",
        "- `contigs='E6-155:70-100'` `pdb='5KQV'` `hotspot='E64,E88,E96'` - diffuse a **binder** of length 70 to 100 (sampled randomly) to chain E and defined hotspot(s).\n",
        "\n",
        "**motif scaffolding**\n",
        " - `contigs='40/A163-181/40'` `pdb='5TPN'`\n",
        " - `contigs='A3-30/36/A33-68'` `pdb='6MRR'` - diffuse a loop of length 36 between two segments of defined PDB ranges.\n",
        "\n",
        "**partial diffusion**\n",
        "- `contigs=''` `pdb='6MRR'` - noise all coordinates\n",
        "- `contigs='A1-10'` `pdb='6MRR'` - keep first 10 positions fixed, noise the rest\n",
        "- `contigs='A'` `pdb='1SSC'` - fix chain A, noise the rest\n",
        "\n",
        "*hints and tips*\n",
        "- `pdb=''` leave blank to get an upload prompt\n",
        "- `contigs='50-100'` use dash to specify a range of lengths to sample from"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
